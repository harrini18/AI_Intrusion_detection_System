{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea78ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (71, 5)\n",
      "Unique Security Labels: [-1  0]\n",
      "DataFrame shape after numeric conversion: (71, 6)\n",
      "DataFrame before dropping NaNs:\n",
      "    RSSI  Channel  Security_Label\n",
      "0    NaN      NaN              -1\n",
      "1  149.0      NaN              -1\n",
      "2    NaN      NaN              -1\n",
      "3   11.0      NaN              -1\n",
      "4    NaN      NaN              -1\n",
      "5  153.0      NaN              -1\n",
      "6    NaN      NaN              -1\n",
      "7    6.0      NaN              -1\n",
      "8    NaN      NaN              -1\n",
      "9    1.0      NaN              -1\n",
      "DataFrame shape after dropping NaNs: (1, 6)\n",
      "Remaining unique values in RSSI and Channel:\n",
      "Unique RSSI values: [-28.]\n",
      "Unique Channel values: [161.]\n",
      "Number of samples: 1\n",
      "Warning: Not enough samples to train a model. Proceeding to save a placeholder model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully in: D:\\Projects\\KOchi\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Specify the path where you want to save the models\n",
    "save_path = \"D:\\\\Projects\\\\KOchi\\\\\"\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/vigne/OneDrive/New folder/2025-02-08T11-10_export.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"], errors='ignore')\n",
    "\n",
    "# Print original DataFrame shape\n",
    "print(f\"Original DataFrame shape: {df.shape}\")\n",
    "\n",
    "def security_mapping(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.lower().strip()\n",
    "        if x in [\"open\", \"unencrypted\", \"u\"]:\n",
    "            return 1\n",
    "        elif x in [\"wpa2-personal\", \"wpa2/wpa3-personal\", \"wpa3-personal\"]:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    return -1\n",
    "\n",
    "df[\"Security_Label\"] = df[\"Security\"].apply(security_mapping)\n",
    "\n",
    "# Check unique values in Security_Label\n",
    "print(f\"Unique Security Labels: {df['Security_Label'].unique()}\")\n",
    "\n",
    "expected_columns = {'RSSI', 'Channel', 'Security_Label'}\n",
    "if not expected_columns.issubset(df.columns):\n",
    "    raise KeyError(f\"Missing required columns. Found: {df.columns.tolist()}\")\n",
    "\n",
    "df['RSSI'] = pd.to_numeric(df['RSSI'], errors='coerce')\n",
    "df['Channel'] = pd.to_numeric(df['Channel'], errors='coerce')\n",
    "\n",
    "# Print shape after converting to numeric\n",
    "print(f\"DataFrame shape after numeric conversion: {df.shape}\")\n",
    "\n",
    "# Print the DataFrame before dropping NaNs\n",
    "print(\"DataFrame before dropping NaNs:\")\n",
    "print(df[['RSSI', 'Channel', 'Security_Label']].head(10))  # Show first 10 rows\n",
    "\n",
    "df = df.dropna(subset=['RSSI', 'Channel'])\n",
    "\n",
    "# Print shape after dropping NaN values\n",
    "print(f\"DataFrame shape after dropping NaNs: {df.shape}\")\n",
    "\n",
    "# Check for remaining unique values\n",
    "print(\"Remaining unique values in RSSI and Channel:\")\n",
    "print(f\"Unique RSSI values: {df['RSSI'].unique()}\")\n",
    "print(f\"Unique Channel values: {df['Channel'].unique()}\")\n",
    "\n",
    "X = df[['RSSI', 'Channel']].values\n",
    "y = df['Security_Label'].values\n",
    "\n",
    "# Check number of samples\n",
    "num_samples = len(X)\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler regardless of the number of samples\n",
    "joblib.dump(scaler, save_path + \"scaler.pkl\")\n",
    "\n",
    "# Train the model if there are enough samples\n",
    "if num_samples < 2:\n",
    "    print(\"Warning: Not enough samples to train a model. Proceeding to save a placeholder model.\")\n",
    "    # Create a placeholder model\n",
    "    rf_model = RandomForestClassifier()  # Placeholder model, not trained\n",
    "else:\n",
    "    rf_model = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42)\n",
    "    X_train, y_train = X_scaled, y  # Use the single sample for training\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model, save_path + \"wifi_model.pkl\")\n",
    "\n",
    "# Create and save a simple neural network model\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model even if there's one sample (not meaningful, but for saving)\n",
    "nn_model.fit(X_scaled, y, epochs=1, batch_size=1)  # Use batch_size=1 for a single sample\n",
    "\n",
    "# Save the neural network model\n",
    "nn_model.save(save_path + \"trained_model.h5\")\n",
    "\n",
    "print(\"Models saved successfully in:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f2125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f49f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
